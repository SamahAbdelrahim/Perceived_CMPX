
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#required packages
```{r packages, message=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(ggplot2)
```

```{r}
pilot_data <- read_csv(here("data", "pilot1.csv"),
                 na = c("NA", ""))
plot_data2 <- read_csv(here("data", "pilot2.csv"),
                 na = c("NA", ""))
pilot_data <- rbind(pilot_data, plot_data2)
pilot_data <- pilot_data %>% select (-c(stimulus))
```

# Pairwise Preference Aggregation
using: Win Rates per Pair and Global Ranking

## Basic Aggregation (Win Rates per Pair)
```{r}
data <- pilot_data

# Preview the data
head(data)
glimpse(data)

# Filter to only comparison trials and select relevant columns
comparisons <- data %>%
  filter(trial_type == "comparison_trial") %>%
  select(subject, leftVideo, rightVideo, response, chosen_object) %>%
  mutate(
    winner = if_else(response == 0, leftVideo, rightVideo),  # Determine winner based on response
    loser = if_else(response == 0, rightVideo, leftVideo)   # For completeness
  )

# Summarize unique pairs and win rates (aggregated across subjects if multiple)
pair_win_rates <- comparisons %>%
  group_by(leftVideo, rightVideo) %>%
  summarise(
    total_comparisons = n(),
    left_wins = sum(response == 0, na.rm = TRUE),
    right_wins = sum(response == 1, na.rm = TRUE),
    left_win_rate = left_wins / total_comparisons,
    right_win_rate = right_wins / total_comparisons,
    .groups = "drop"
  ) %>%
  arrange(desc(total_comparisons))  # Sort by most frequent pairs

pair_win_rates


# Simple overall win counts per video (basic ranking)
overall_wins <- comparisons %>%
  count(winner) %>%
  rename(video = winner, total_wins = n) %>%
  arrange(desc(total_wins))

# View overall wins (crude ranking: higher wins = more complex)
overall_wins


```

## Advanced Ranking with Bradley-Terry Model

```{r}
# Install if needed: install.packages("BradleyTerry2")
library(BradleyTerry2)  # For Bradley-Terry model

# Prepare data for Bradley-Terry (needs a "contests" format: winner ~ loser, with counts)
# Assume one "win" per comparison; group to count if duplicates
bt_data <- comparisons %>%
  group_by(winner, loser) %>%
  summarise(wins = n(), .groups = "drop") %>%
  ungroup()

# Fit the model (videos as "players")
bt_model <- BTm(
  cbind(wins, 0),  # Wins matrix (assuming no ties)
  player1 = bt_data$winner,
  player2 = bt_data$loser,
  formula = ~ .,
  id = "player"
)

# Get abilities (ranked complexity scores; higher = more complex)
bt_abilities <- BTabilities(bt_model)
bt_ranked <- as_tibble(bt_abilities) %>%
  rownames_to_column("video") %>%
  select(video, ability, se) %>%
  arrange(desc(ability))  # Rank from most to least complex

# View ranked videos
bt_ranked
# Example from sample (scores will vary; small data may cause warnings about convergence):
# video        ability   se
# File 10.mp4  1.0986    1.0986  # Highest (beat File 4)
# File 28.mp4  1.0986    1.0986  # Beat File 22
# File 25.mp4  1.0986    1.0986  # Beat File 9
# File 4.mp4   0.0000    0.0000
# File 22.mp4  0.0000    0.0000
# File 9.mp4   0.0000    0.0000

# Plot the rankings (optional)
ggplot(bt_ranked, aes(x = reorder(video, ability), y = ability)) +
  geom_point() +
  geom_errorbar(aes(ymin = ability - se, ymax = ability + se), width = 0.2) +
  coord_flip() +
  labs(title = "Bradley-Terry Complexity Ranking", x = "Video", y = "Complexity Score")

```
